{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8b92fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pdfminer.six\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d25e3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed349b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_skills(pdf_file):\n",
    "    # !pip install pdfminer.six\n",
    "    \n",
    "    from pdfminer.high_level import extract_text\n",
    "#     get text from pdf\n",
    "    text = extract_text(\"Aman resume for y2.pdf\").lower()\n",
    "    \n",
    "#     get keywords\n",
    "    keywords = re.findall(r'[a-zA-Z]\\w+',text.lower())\n",
    "    \n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    # Download NLTK stopwords corpus\n",
    "    # nltk.download('stopwords')\n",
    "    # nltk.download('punkt')\n",
    "    token_text = word_tokenize(text)\n",
    "    stop_words = stopwords.words('english')\n",
    "    clean_text = []\n",
    "    for i in token_text:\n",
    "        if i not in stop_words:\n",
    "            clean_text.append(i)\n",
    "    clean_text = \" \".join(clean_text)\n",
    "    \n",
    "    pattern = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "    clean_text = re.sub(pattern, '', clean_text).replace(\"\\n\", \"\")\n",
    "    \n",
    "        # Define a regular expression pattern to match numbers\n",
    "    pattern2 = r'\\d+'\n",
    "\n",
    "    # Remove numbers from the text using regex substitution\n",
    "    text_without_numbers = re.sub(pattern2, '', clean_text)\n",
    "    \n",
    "    return text_without_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4ff71242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aman kumar student maharshi dayanand university btech computer science nd year  github  linkedin  twitter  hashnode projects mlops project endtoend chicken disease classication a deep learning project using mlops tools  dvc  github actions  deployment aws  finetuning deployed llm model tuned large language model deployed   ak  gmailcom skills  kubernetes  go  mlflow  kubeflow  deep learning  helm  argocd  githubaction  mlops  tensorow  deep learning  machine learning  docker  prometheus created  chatbots finance cricket   cricket lover give live scores nd finance related work   huggingface  transformers  weights  bias mlops project endtoend till deployment ks githubactions  complete deployment end end fetch data  train model  docker push hub  deployment ks manage via cncf rancher develop anime recommender system automates workows using github actions  predicts cartoon series based interest increases user watch time    multidocument summarization  created end end multidocument summarization implement automation experience internship data science dataknobs june  aws sagemaker  deployment gcp cloud run awards microsoft student ambassador  group campus leaders eager help fellow students  create robust tech communities develop technical career skills future  kaggle certication data science   certication data science  ibm certication coursera  postman rest apis golden badge experts apis  build llm models build generative ai models  gssoc  ssoc mentee open source contribution  zoweclientsdk  mindsdb  suse  google cloud facilitator mayjuly cloud professional worked google cloud platform  earned  gcp badges  students  education maharishi dayanand university  rohtakbachelor technology computer science august   august  rajokari institute technology  delhi  diploma august   august  sarvodaya bal vidyalaya  delhi  th april  april  contributed open source zoweclientsdk  mindsdb  suse contributed organizations  implement many features functionality  x bugs  improves user experience    google facilitator completed  times  program  earned  google cloud badges learned new tech stu  docker  kubernetes  yaml  google cloud platform go  makele  shell  plpgsql '"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_skills(\"Aman resume for y2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cfa3c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(list(set(keywords)),columns=['keywords'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d419cf4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52691647",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "token_text = word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2f4b8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "clean_text = []\n",
    "for i in token_text:\n",
    "    if i not in stop_words:\n",
    "        clean_text.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbaaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "71d5fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = \" \".join(clean_text)\n",
    "# clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "042b953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "clean_text = re.sub(pattern, '', clean_text).replace(\"\\n\", \"\")\n",
    "rm_digit = re.compile(r'\\b\\d{10}\\b')  # Remove 10-digit numbers\n",
    "clean_text = re.sub(rm_digit, \"\", clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0dab504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    # Define a regular expression pattern to match numbers\n",
    "    pattern = r'\\d+'\n",
    "\n",
    "    # Remove numbers from the text using regex substitution\n",
    "    text_without_numbers = re.sub(pattern, '', text)\n",
    "\n",
    "    return text_without_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0c3da449",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = remove_numbers(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a1bbe7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def remove_person_names(text):\n",
    "    # Process the text using spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Remove entities identified as PERSON\n",
    "    filtered_text = ' '.join([token.text for token in doc if token.ent_type_ != 'PERSON'])\n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "62b193ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aman maharshi dayanand university btech computer science nd year   github   linkedin   twitter   hashnode projects mlops project endtoend chicken disease classication a deep learning project using mlops tools   dvc   github actions   deployment aws   finetuning deployed llm model tuned large language model deployed    ak   gmailcom skills   kubernetes   go   mlflow   kubeflow   deep learning   helm   argocd   githubaction   mlops   tensorow   deep learning   machine learning   docker   prometheus created   chatbots finance cricket    cricket lover give live scores nd finance related work    huggingface   transformers   weights   bias mlops project endtoend till deployment ks githubactions   complete deployment end end fetch data   train model   docker push hub   deployment ks manage via cncf rancher develop anime recommender system automates workows using github actions   predicts cartoon series based interest increases user watch time     multidocument summarization   created end end multidocument summarization implement automation experience internship data science dataknobs june   aws sagemaker   deployment gcp cloud run awards microsoft student ambassador   group campus leaders eager help fellow students   create robust tech communities develop technical career skills future   kaggle certication data science    certication data science   ibm certication coursera   postman rest apis golden badge experts apis   build llm models build generative ai models   gssoc   ssoc mentee open source contribution   zoweclientsdk   mindsdb   suse   google cloud facilitator mayjuly cloud professional worked google cloud platform   earned   gcp badges   students   education maharishi dayanand university   rohtakbachelor technology computer science august    august   rajokari institute technology   delhi   diploma august    august   sarvodaya bal vidyalaya   delhi   th april   april   contributed open source zoweclientsdk   mindsdb   suse contributed organizations   implement many features functionality   x bugs   improves user experience     google facilitator completed   times   program   earned   google cloud badges learned new tech stu   docker   kubernetes   yaml   google cloud platform go   makele   shell   plpgsql'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_person_names(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13c98948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aman kumarstudent at maharshi dayanand university btech incomputer science 2nd yeargithub  '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_personal_info(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3fd55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
